[
["multiple-traits-models.html", "6 Multiple traits models 6.1 Introducing innovations 6.2 Optimising the code 6.3 The distribution of popularity 6.4 Analytical appendix 6.5 Further readings", " 6 Multiple traits models In all the scenarios we considered so far, individuals could posses one of two cultural traits, \\(A\\) or \\(B\\). This is a useful simplification, and it represents cases in which cultural traits can be modeled as binary choices, such as being in favour or against a particular policy, choosing between Beatles and Rolling Stones (and no one else!), eating meat or not, and similar. In other cases, however, there are many options: there are many books to read, movies to watch, and, despite our Beatles and Rolling Stones example, many musical bands one can choose to listen to. What does it happen when we copy others’ choices? To simplfy, we are again assuming unbiased copying as in the [first chapter][Unbiased transmission]: all traits are equivalent and we do not copy preferentially from any individual, but just pick them at random. The first modification we need to do in the code concerns how traits are represented. Since we have an undetermined number of possible traits we can not use the two letters \\(A\\) abd \\(B\\), but we will use instead numbers, so that traits will be now referred as trait “1”, trait “2”, trait “2”, etc. To start with, we can initliase each individual with a trait randomly chosen between “1” and “100”. library(tidyverse) set.seed(111) N &lt;- 100 population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) As usual, you can inspect the population tibble by writing its name. population ## # A tibble: 100 x 1 ## trait ## &lt;int&gt; ## 1 60 ## 2 73 ## 3 38 ## 4 52 ## 5 38 ## 6 42 ## 7 2 ## 8 54 ## 9 44 ## 10 10 ## # … with 90 more rows The basic code of the simulation is similar to the code in the [first chapter][Unbiased transmission], but what the output should be? Until now, we just needed to save the freuquency of one of the two trait, but now we need the frequencies of all N traits to have an idea of what happens in the simulation. Another modification in the code above concerns how we measure the frequency of the traits in each generation. The function hist(), as the name suggests, is generally used to plot an histogram of the data. However, it can be used, adding the argument plot = FALSE, to only calculate what we would need for an histogram, without producing the graph. Among the outputs produced, density gives the relative frequencies of the binned data, which is what we are interested in. multiple_traits &lt;- function(N, t_max) { output &lt;- tibble(trait = as.factor(rep(1:N, each = t_max)), generation = rep(1:t_max, N), p = rep(NA, t_max * N)) population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) # create first generation output[output$generation == 1, ]$p &lt;- hist(population$trait, 0:N, plot = FALSE)$density # add first generation&#39;s p for all traits for (t in 2:t_max) { previous_population &lt;- population # copy individuals to previous_population tibble population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # randomly copy from previous generation output[output$generation == t, ]$p &lt;- hist(population$trait, 0:N, plot = FALSE)$density # get p for all traits and put it into output slot for this generation t } output # export data from function } Finally, the function to plot the output is similar to what we have already done when plotting multiple runs, with the difference that now the colored lines do not represent different runs, but different traits, as indicated below by aes(colour = trait). We also need to specify that traits should not be interpreted The new line theme(legend.position = &quot;none&quot;) simply tells to not include the legends in the graph, as it is not informative, and it would show 100 colors, one for each trait. plot_multiple_traits &lt;- function(data_model) { ggplot(data = data_model, aes(y = p, x = generation)) + geom_line(aes(colour = trait)) + ylim(c(0, 1)) + theme_bw() + theme(legend.position = &quot;none&quot;) } As usual, we can call the function and see what happens: data_model &lt;- multiple_traits(N = 100, t_max = 200) plot_multiple_traits(data_model) In the majority of cases, in 200 generations, only one or two traits are still present in the population and, if you increase \\(t_\\text{max}\\) for example to 1000, virtually all runs end up with only a single trait reaching fixation: data_model &lt;- multiple_traits(N = 100, t_max = 200) plot_multiple_traits(data_model) This is similar to what we saw when considering the analogous situation with only two traits, \\(A\\) and \\(B\\): with unbiased copying and relative small populations, drift is a powerful force, that quickly erodes cultural diversity. This is similar to what we saw when considering the analogous situation with only two traits, \\(A\\) and \\(B\\): with unbiased copying and relative small populations, drift is a powerful force, that quickly erodes cultural diversity. As we already discussed, increasing \\(N\\) limits the effect of drift. You can experiment with various values for \\(N\\) and \\(t_{max}\\). However, the general point is that variation is gradually lost in all cases. How can we counterbalance the homogenizing effect that drift has in small and isolated population, such as the one we are simulating? 6.1 Introducing innovations An option is to introduce new traits with individual innovations. We can imagine that, at each time step, a proportion of individuals, \\(\\mu\\) (we use the same notation that we used for mutation in chapter 2), introduces a new trait in the population. The remaining proportion of individuals, \\(1-\\mu\\) copy at random from others, as before. We can start with a small value, such as \\(\\mu=0.01\\). Since \\(N=100\\), this means that at each generation, on average, one new trait will be introduced in the population. Let’s see how we can write what happens at each generation: mu &lt;- 0.01 last_trait &lt;- max(population) # record what is the last trait introduced in the population previous_population &lt;- population # copy the population tibble to previous_population tibble population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # randomly copy from previous generation&#39;s individuals innovators &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) # select the innovators population[innovators,]$trait &lt;- (last_trait + 1):(last_trait + sum(innovators)) # replace innovators&#39; traits with new traits There are two modifications here. First, we need to select who are the innovators. For that, we use again the function sample(), biased by \\(\\mu\\), picking \\(TRUE\\) (corresponding to be an innovator) or \\(FALSE\\) (keeping the copied cultural trait) for \\(N\\) times. Second, we need to keep track of the new introduced traits. In order to do so, we record at the beginning of each generation what is the “name” of the last trait introduced (at the beginning, with \\(N=100\\), it will be “100”, as we initialise each individual of the population with a different trait). When new traits are introduced, we call them with consecutive numbers: the first new traits will be called “101”, the second “102” and so on. We can now, as usual, wrap everything in a function. multiple_traits_2 &lt;- function(N, t_max, mu) { max_traits &lt;- N + N * mu * t_max output &lt;- tibble(trait = as.factor(rep(1:max_traits, each = t_max)), generation = rep(1:t_max, max_traits), p = rep(NA, t_max * max_traits)) population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) # create first generation output[output$generation == 1, ]$p &lt;- hist(population$trait, 0:N, plot = FALSE)$density # add first generation&#39;s p for all traits for (t in 2:t_max) { last_trait &lt;- max(population) # record what is the last trait introduced in the population previous_population &lt;- population # copy individuals to previous_population tibble population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # randomly copy from previous generation&#39;s individuals # randomly copy from previous generation if (last_trait &lt; max_traits) { innovators &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) # select the innovators if( sum(innovators) &gt; 0){ population[innovators,]$trait &lt;- (last_trait + 1):(last_trait + sum(innovators)) # replace innovators&#39; traits with new traits } } output[output$generation == t, ]$p &lt;- hist(population$trait, 0:max_traits, plot = FALSE)$density # get p for all traits and put it into output slot for this generation t } output # export data } You should be familiar with more or less everything within this function, with one exception: the introduction of the new quantity max_traits. This is a trick we are using to avoid making the code too heavy to run. Our output tibble, as you remember, record all the frequencies of all traits. When programming, a good rule-of-thumb is to avoid to modify dynamically the size of your data structures, such as, for example, adding columns or rows to pre-existing matrices, as in our case. In our simulation, at every generation, there is some probability that a new trait will be introduced so that, as a consequence, we would need to add a columns in the output tibble to record its frequency. To avoid this, we are creating a bigger tibble from the beginning, with columns for many possible new traits. How many is ‘many’? We do not know, but an estimate is that we will need columns for the initial traits (\\(N\\)), plus around \\(N\\mu\\) traits for each generation. To be sure to not exceed this number, we wrapped the innovation instruction in the if( last_trait &lt; max_traits ) control. As a consequence, it is possible that in some runs, in the very last generations, innovations will not be permitted. For many purposes, this does not change the outcome of the simulation, and for the time being is better than modify dynamically our raw_output. Let’s now run the function with an innovation rate \\(\\mu=0.01\\), again with a population of 100 individuals, and for 200 generations. data_model &lt;- multiple_traits_2(N = 100, t_max = 200, mu = 0.01) plot_multiple_traits(data_model) There should be now more traits at non-zero frequency at the end of the simulation that what happened when innovations were not possible. We can actually check the exact number, by inspecting how many frequencies higher than 0 are in the last row of our matrix: sum(filter(data_model, generation==200)$p &gt; 0) ## [1] 10 What happens if we increase the number of generations, or time steps, to 1000, as we did before? data_model &lt;- multiple_traits_2(N = 100, t_max = 1000, mu = 0.01) plot_multiple_traits(data_model) As you can see in the plot, there should still be various traits that have frequencies higher than 0, even after 1000 generations. Again, we can check it sum(filter(data_model, generation==1000)$p &gt; 0) ## [1] 10 Innovation, in sum, allows the maintenance of variation even in small populations. 6.2 Optimising the code BACK TO MATRICES 6.3 The distribution of popularity TO DO An interesting aspect of these simulations is that, even if all traits are equal and individuals are not biased, few traits, for random reasons, are more successful than the majority of the others. A way to visualise the relative popularity of all traits is to plot their cumulative frequencies, that is the sum of the frequencies over all generations. Given our matrix, it is easy to calculate them by summing each column: # cumulative &lt;- (sort(colSums(data_model), decreasing = TRUE)) / sum(data_model) We also sort them from the highest to the lowest frequency, and we normalise all the values so that their sum is equal to 1. Now we can plot them: # output &lt;- tibble(cumulative) # # ggplot(data = output, aes(x = seq_along(cumulative), y = cumulative)) + # geom_point() + # theme_bw() + # labs( # title = &quot;Unbiased transmission&quot;, # x = &quot;trait&quot;, # y = &quot;cumulative frequency&quot; # ) explain the plot loglog Bentley stile? example of function that does multiple runs without storing the big matrix each time, but only the output we are interested in (e.g. number of traits, max frequency, etc. to compare the effect of parameters) 6.4 Analytical appendix 6.5 Further readings "]
]
