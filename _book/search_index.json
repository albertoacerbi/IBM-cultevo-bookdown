[
["biased-transmission-indirect-bias-frequency.html", "3 Biased transmission (indirect bias: frequency) 3.1 The logic of conformity 3.2 Testing conformist transmission 3.3 Summary of the model 3.4 Analytic appendix", " 3 Biased transmission (indirect bias: frequency) 3.1 The logic of conformity In Chapter 3 we looked at the case where one cultural trait is intrinsically more likely to be copied than another trait. Here we will start to look the other kind of biased transmission, when traits are equivalent, but individuals are more likely to adopt a trait according to the characteristics of the demonstrators, the other individuals who already have it. (As we mentioned previously, these are often called ‘indirect’ or ‘context’ bias). A first possiblity is that we may be influenced by the frequency of the trait in the population: how many other individuals already have the traits? Cconformity (or ‘positive frequency dependent bias’) is the case most studied (the opposite case, anti-conformity or negative frequency dependent bias is also possible, even though probably more uncommon in real life). Here, individuals are disproportionately more likely to adopt the most common trait in the population, irrespective of its intrinsic characteristics. For example, imagine trait \\(A\\) has a frequency of 0.7 in the population, with the rest possessing trait \\(B\\). An unbiased learner would adopt trait \\(A\\) with a probability exactly equal to 0.7. This is unbiased transmission, and is what happens the model described in ([Chapter 1][Unbiased transmission]: by picking a member of the previous generation at random, the probability of adoption is equal to the frequency of that trait amongst the previous generation. A conformist learner, on the other hand, would adopt trait \\(A\\) with a probability greater than 0.7. In other words, common traits get an ‘adoption boost’ relative to unbiased transmission. Uncommon traits get an equivalent ‘adoption penalty’. The magnitude of this boost or penalty can be controlled by a parameter, which we will call \\(D\\). Let’s keep things simple in our model. Rather than assuming that individuals sample across the entire population, which in any case might be implausible in large populations, let’s assume they pick only three demonstrators at random. Why three? This is the minimum number of demonstrators that can yield a majority (i.e. 2 vs 1), which we need in order to implement conformity. When two demonstrators have one trait and the other demonstrator has a different trait, we want to boost the probability of adoption for the majority trait, and reduce it for the minority trait. We can specify the probability of adoption as follows: Table 1: Probability of adopting trait \\(A\\) for each possible combination of traits amongst three demonstrators Demonstrator 1 Demonstrator 2 Demonstrator 3 Probability of adopting trait \\(A\\) \\(A\\) \\(A\\) \\(A\\) 1 \\(A\\) \\(A\\) \\(B\\) \\(A\\) \\(B\\) \\(A\\) \\(2/3 + D/3\\) \\(B\\) \\(A\\) \\(A\\) \\(A\\) \\(B\\) \\(B\\) \\(B\\) \\(A\\) \\(B\\) \\(1/3 - D/3\\) \\(B\\) \\(B\\) \\(A\\) \\(B\\) \\(B\\) \\(B\\) 0 The first row says that when all demonstrators have trait \\(A\\), then trait \\(A\\) is definitely adopted. Similarly, the bottom row says that when all demonstrators have trait \\(B\\), then trait \\(A\\) is never adopted, and by implication trait \\(B\\) is always adopted. For the three combinations where there are two \\(A\\)s and one \\(B\\), the probability of adopting trait \\(A\\) is \\(2/3\\), which it would be under unbiased transmission (because two out of three demonstrators have \\(A\\)), plus the conformist adoption boost specified by \\(D\\). As \\(D\\) varies from 0 to 1 is divided by three, so that the maxmimum probability of adoption is equal to 1. Similarly, for the three combinations where there are two \\(B\\)s and one \\(A\\), the probability of adopting \\(A\\) is 1/3 minus the conformist adoption penalty specified by \\(D\\). Let’s implement these assumptions in the kind of individual based model we’ve been building so far. As before, assume \\(N\\) individuals each of whom possess one of two traits \\(A\\) or \\(B\\). The frequency of \\(A\\) is denoted by \\(p\\). The initial frequency of \\(A\\) in generation \\(t = 1\\) is \\(p_0\\). Rather than going straight to a function, let’s go step by step. First we’ll specify our parameters, \\(N\\) and \\(p_0\\) as before, plus the new conformity parameter \\(D\\). We also create the usual population tibble and fill it with \\(A\\)s and \\(B\\)s in the proportion specified by \\(p_0\\), again exactly as before. library(tidyverse) set.seed(111) N &lt;- 100 p_0 &lt;- 0.5 D &lt;- 1 population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # create first generation Now we create another tibble, called demonstrators that picks, for each new individual in the next generation, three demonstrators at random from the current population of individuals. It therefore needs three columns/variables, one for each of the demonstrators, and \\(N\\) rows, one for each individual. We fill each column with randomly chosen traits from the population tibble. We can have a look at demonstrators entering its name in the R console. # create dataframe with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) demonstrators ## # A tibble: 100 x 3 ## dem1 dem2 dem3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B B B ## 2 B A A ## 3 A B A ## 4 A B B ## 5 A B B ## 6 A B B ## 7 A B B ## 8 A B A ## 9 A A A ## 10 A B B ## # … with 90 more rows Think of each row here as containing the traits of three randomly-chosen demonstrators chosen by each new next-generation individual. Now we want to calculate the probability of adoption of \\(A\\) for each of these three-trait demonstrator combinations. First we need to get the number of \\(A\\)s in each combination. Then we can replace the traits in population based on the probabilities in Table 1. When all demonstrators have \\(A\\), we set to \\(A\\). When no demonstrators have \\(A\\), we set to \\(B\\). When two out of three demonstrators have \\(A\\), we set to \\(A\\) with probability \\(2/3 + D/3\\) and \\(B\\) otherwise. When one out of three demonstrators have \\(A\\), we set to \\(A\\) with probability \\(1/3 - D/3\\) and \\(B\\) otherwise. # get the number of As in each 3-dem combo num_As &lt;- rowSums(demonstrators == &quot;A&quot;) population$trait[num_As == 3] &lt;- &quot;A&quot; # for dem combos with all As, set to A population$trait[num_As == 0] &lt;- &quot;B&quot; # for dem combos with no As, set to B prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # when A is a majority, 2/3 if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # when A is a minority, 1/3 if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } To check it works, we can add the new population tibble as a column to demonstrators and have a look at it. This will let us see the three demonstrators and the resulting new trait side by side. # for testing only, add the new traits to the demonstrator dataframe and show it demonstrators &lt;- add_column(demonstrators, new_trait = population$trait) demonstrators ## # A tibble: 100 x 4 ## dem1 dem2 dem3 new_trait ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B B B B ## 2 B A A A ## 3 A B A A ## 4 A B B B ## 5 A B B B ## 6 A B B B ## 7 A B B B ## 8 A B A A ## 9 A A A A ## 10 A B B B ## # … with 90 more rows Because we set \\(D=1\\) above, the new trait is always the majority trait amongst the three demonstrators. This is perfect conformity. We can weaken conformity by reducing \\(D\\). Here an example with \\(D=0.5\\). All the code is the same of what we already discussed above. N &lt;- 100 p_0 &lt;- 0.5 D &lt;- 0.1 population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # create first generation # create dataframe with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) # get the number of As in each 3-dem combo num_As &lt;- rowSums(demonstrators == &quot;A&quot;) population$trait[num_As == 3] &lt;- &quot;A&quot; # for dem combos with all As, set to A population$trait[num_As == 0] &lt;- &quot;B&quot; # for dem combos with no As, set to B prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # when A is a majority, 2/3 if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # when A is a minority, 1/3 if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } # for testing only, add the new traits to the demonstrator dataframe and show it demonstrators &lt;- add_column(demonstrators, new_trait = population$trait) demonstrators ## # A tibble: 100 x 4 ## dem1 dem2 dem3 new_trait ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B A A B ## 2 A B B B ## 3 A A A A ## 4 B B B B ## 5 A B A B ## 6 A A B A ## 7 B B A A ## 8 A B B B ## 9 B A A A ## 10 B B B B ## # … with 90 more rows Now that conformity is weaker, sometimes the new trait is not the majority amongst the three demonstrators, as it happens, for example, for the first individual. 3.2 Testing conformist transmission As we have done in the previous chapters, it is now time to put all together into a function to test what happens over multiple generations and in multiple runs. There is nothing new in the code below, which is a combination of the code we already wrote in ([Chapter 1][Unbiased transmission]) and the bits of code for conformity we discussed above. conformist_transmission &lt;- function (N, p_0, D, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = rep(NA, t_max * r_max), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # create first generation output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N # add first generation&#39;s p for run r for (t in 2:t_max) { # create dataframe with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) # get the number of As in each 3-dem combo num_As &lt;- rowSums(demonstrators == &quot;A&quot;) population$trait[num_As == 3] &lt;- &quot;A&quot; # for dem combos with all As, set to A population$trait[num_As == 0] &lt;- &quot;B&quot; # for dem combos with no As, set to B prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # when A is a majority, 2/3 if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # when A is a minority, 1/3 if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N # get p and put it into output slot for this generation t and run r } } output # export data from function } We can now test the function with perfect conformity (\\(D=1\\)) and plot it (again we use the function plot_multiple_runs() we wrote in [Chapter 1][Unbiased transmission]). data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.5, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Here we should see some lines going to \\(p = 1\\), and some lines going to \\(p = 0\\). Conformity acts to favour the majority trait. This will depend on the initial frequency of \\(A\\) in the population. In different runs with \\(p_0 = 0.5\\), sometimes there will be slightly more \\(A\\)s, sometimes slightly more \\(B\\)s (remember, in our model this is probabilistic, like flipping coins, so initial frequencies will rarely be precisely 0.5). What does it happen if we set \\(D = 0\\)? data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.5, D = 0, t_max = 50, r_max = 10) plot_multiple_runs(data_model) This model is equivalent to unbiased transmission. As for the simulations described in [Chapter 1][Unbiased transmission], with a sufficiently large \\(N\\), the frequencies fluctuate around \\(p = 0.5\\). This underlines the effect of conformity. Whith unbiased transmission, majority traits are favoured as they are copied in proportion to their frequency (incidentally, it is for this reason that ‘copying the majority’ is not a good description of conformity in the technical sense of cultural evolution: even with unbiased copying the majority trait is copied more than the minority one), but they reach fixation only in small population. With conformity, instead, the majority trait is copied with a probability higher than its frequency, so that conformity drives traits to fixation as they become more and more common. As an aside, note that the last two graphs have roughly the same thick black mean frequency line, which hovers around \\(p = 0.5\\). This highlights the dangers of looking at means alone. If we hadn’t plotted the individual runs and relied solely on mean frequencies, we might think that \\(D = 0\\) and \\(D = 1\\) gave identical results. But in fact, they are very different. Always look at the underlying distribution that generates means. Now let’s explore the effect of changing the initial frequencies by changing \\(p_0\\), and adding conformity back in. data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.55, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) When \\(A\\) starts off in a slight majority (\\(p_0 = 0.55\\)), all of the runs result in \\(A\\) going to fixation (notice this depends on the random initialisation: you can try and change the number in set.seed() to see what happens. In any case, most if not all runs should result in \\(A\\) going to fixation). Now let’s try the reverse. data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.45, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) When \\(A\\) starts off in a minority (\\(p_0 = 0.45\\)), all runs result in \\(A\\) disappearing. These last two graphs show how initial conditions affect conformity. Whichever trait is more common is favoured by conformist transmission. 3.3 Summary of the model In this chapter, we explored conformist biased cultural transmission. This is where individuals are disproportionately more likely to adopt the most common trait among a set of demonstrators. We can contrast this indirect bias with the direct (or content) biased transmission from Chapter 3, where one trait is intrinsically more likely to be copied. With conformity, the traits have no intrinsic attractiveness and are preferentially copied simply because they are common. We saw how conformity increases the frequency of whichever trait is more common. Initial trait frequencies are important here: traits that are initially more common typically go to fixation. This in turn makes stochasticity important, which in small populations can affect initial frequencies. We also discussed the subtle, but fundamental, difference between unbiased copying and conformity: in both majority traits end up to be favoured, but it is only with conformity that they are disproportionally favoured. This allows for traits’ fixation also in large populations but also, as we will explore later, makes majority traits resitant to external disturbances, such as the introduction of other traits from innovation or circualtion of people (migration). 3.4 Analytic appendix Let’s revise Table 1 to add the probabilities of each combination of three demonstrators coming together, assuming they are picked at random. These probabilities can be expressed in terms of \\(p\\), the frequency of \\(A\\), and \\((1 - p)\\), the frequency of \\(B\\). Table 2 adds this column. Table 2: Full adoption probability table for trait \\(A\\) under conformist transmission Dem 1 Dem 2 Dem 3 Prob of adopting \\(A\\) Prob of combination forming \\(A\\) \\(A\\) \\(A\\) 1 \\(p^3\\) \\(A\\) \\(A\\) \\(B\\) \\(A\\) \\(B\\) \\(A\\) \\(2/3 + D/3\\) \\(p^2(1-p)\\) \\(B\\) \\(A\\) \\(A\\) \\(A\\) \\(B\\) \\(B\\) \\(B\\) \\(A\\) \\(B\\) \\(1/3 - D/3\\) \\(p(1-p)^2\\) \\(B\\) \\(B\\) \\(A\\) \\(B\\) \\(B\\) \\(B\\) 0 \\((1-p)^3\\) To get the frequency of \\(A\\) in the next generation, \\(p&#39;\\), we multiply, for each of the eight rows in Table 2, the probability of adopting \\(A\\) by the probability of that combination forming (i.e. the final two columns in Table 2), and add up all of these eight products. After rearranging, this gives the following recursion: \\[p&#39; = p + Dp(1-p)(2p-1) \\hspace{30 mm}(4.1)\\] We can plot the recursion, with weak conformity (\\(D = 0.1\\)) and slightly more \\(A\\) in the initial generation (\\(p_0 = 0.55\\)) as we did previously in the simulation: t_max &lt;- 150 p_0 &lt;- 0.51 D &lt;- 0.1 pop_analytical &lt;- tibble(p = rep(NA, t_max), generation = 1:t_max) pop_analytical$p[1] &lt;- p_0 for (i in 2:t_max) { pop_analytical$p[i] &lt;-pop_analytical$p[i - 1] + D * pop_analytical$p[i - 1] * (1 - pop_analytical$p[i - 1]) * (2 * pop_analytical$p[i - 1] - 1) } ggplot(data = pop_analytical, aes(y = p, x = generation)) + geom_line() + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;p (proportion of individuals with trait A)&quot;) You can change the values of \\(p_0\\) in the code above, (for example less than 0.5, and equal to 0.5) and reproduce the results of the other simulations above. Finally, we can use the recursion equation to generate a plot that has become a signature for conformity in the cultural evolution literature. The following code plots, for all possible values of \\(p\\), the probability of adopting \\(p\\) in the next generation. Note first two new R commands. We use the function seq() to generate a sequence of 101, equally spaced, numbers from 0 to 1, and we use a new ggplot ‘geom’. geom_abline() draws a custom line for which we can pass slop and intercept, as well as other aesthetic properties (such as here linetype = &quot;dashed&quot;). D &lt;- 1 conformity_p_adopt &lt;- tibble( p = seq(from = 0, to = 1, length.out = 101), p_next = p + D * p * (1 - p) * (2 * p - 1)) ggplot(data = conformity_p_adopt, aes(y = p_next, x = p)) + geom_line() + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;) + ylim(c(0, 1)) + theme_bw() + labs(x = &quot;frequency of A (p)&quot;, y = &quot;probability of adopting A (p&#39;)&quot;) This plot encapsulates the process of conformity. The dotted line shows unbiased transmission: the probability of adopting \\(A\\) is exactly equal to the frequency of \\(A\\) in the population. The s-shaped solid curve shows conformist transmission. When \\(A\\) is common (\\(p &gt; 0.5\\)), then the curve is higher than the dotted line: there is a disproportionately higher probability of adopting \\(A\\). When \\(A\\) is uncommon (\\(p &lt; 0.5\\)), then the curve is lower than the dotted line: there is a disproportionately lower probability of adopting \\(A\\). "]
]
