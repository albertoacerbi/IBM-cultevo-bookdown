
# Biased transmission (indirect bias: demonstrator)

In the two previous chapters, we started to examine biased transmission, both based on the characteristics of the traits (or [direct bias][Biased transmission (direct bias)]) and on the characteristics of the population. The latter can result from taking into account the frequency of a trait (as we did for [conformity][Biased transmission (indirect bias: frequency)]) or from taking into account specific features of the demonstrators, which we will look at in this chapter (demonstrator bias is also called 'model bias' in cultural evolution). 

Whereas the simulations we realised previously are fairly standard, indirect demonstrator-based biased transmission can be implemented in several different ways. Demonstrator biases can result when individuals decide whether to copy or not by taking into account any features of the demonstrators, as long as it is not directly tied to the traits. The most studied demonstrator bias is prestige bias, where individuals are more likely to copy from demonstrators that are considered more 'prestigious', for example because other individuals show deference to them. Alternatively, individuals can copy the demonstrators that are more successful, independently from how others judge them, or they can copy individuals that are more similar to them, or older (or younger), and so on. The crux is that the decision is not directly linked to the cultural trait itself.

## A simple demonstrator bias

To implement a simple version of demonstrator-biased cultural transmission, we first need to assume that there are some intrinsic differences in the population. Up until now, our populations were described only by the traits they possessed. We now want that individuals have a feature by which some of them can be distinguished from others, and, as a consequence, being more liked to be copied. We can call this feature 'status'. An individual's status is a binary variable that could stand for whether they are prestigious or not, old (young) or not (assuming that the time frame of the simulations is sufficiently short) or any other features that do not change, and that other individuals can use to decide whether to copy from them or not. We can  have a parameter $p_s$ that determines the probability an individual have an high or a low status. 

```{r 5.1}
library(tidyverse)
set.seed(111)

N <- 100
p_0 <- 0.5
p_s <- 0.05

population <- tibble(trait = sample(c("A", "B"), N, replace = TRUE, prob = c(p_0, 1 - p_0)),
                     status = sample(c("high", "low"), N, replace = TRUE, prob = c(p_s, 1 - p_s))) 
```

We can inspect the tibble by typing its name in the R console

```{r 5.2}
population
```

With $p_s=0.05$ around 5 individuals in a population of 100 will have high status. In this specific case, one of them is individual 10, so it will be one of the individuals that will be likely to be copied more from. 

How should the status used to decide whether to copy or not? Again, there are various possibilities. An intuitive way is to assume that the probabilities to pick high-status and low-status individuals as demonstrators are different. So far, when using the function `sample()` to select demonstrators, we did not include any specific probability, so that each individual of the previous generation had the same likelihood to be selected. However, we can pass to the function a vector of probabilities to weight the choice. We can assume that the probability to select high status individuals as demonstrators is always equal to 1, but the probability to select low-status individuals is encoded by a further parameter, $p_\text{low}$: when $p_\text{low}=1$, the simulations correspond to unbiased transmission, as everybody has the same probability to be chosen, while with $p_\text{low}=0$, there is a strict model bias, where only high-status individuals can be selected as demonstrators. 

To implement this, we first store in `p_demonstrator` the probabilities to be copied for each member of the population: 

```{r 5.3}
p_low <- 0.01

p_demonstrator <- rep(1,N)
p_demonstrator[population$status == "low"] <- p_low

```

After that, we sample the traits in the population using these probabilities. Notice the instruction `if(sum(p_demonstrator) > 0)`: this is necessary in case there are not high-status individuals (for example with $p_s\simeq0$) and the probability to select demonstrators from low-status one is equal to 0. In this case, the total probability would be also equal to 0, and it would generate an error when the function is run. With this instruction, instead, no copying happens, which is what we would expect in this situation. 

```{r 5.4}
if(sum(p_demonstrator) > 0){
  
  demonstrator_index <- sample (N, prob = p_demonstrator, replace = TRUE)
  
  population$trait <- population$trait[demonstrator_index]
  
}
```

As usual, we can wrap everything in a function.

```{r 5.5}
biased_transmission_demonstrator <- function(N, p_0, p_s, p_low, t_max, r_max) {
  
  output <- tibble(generation = rep(1:t_max, r_max), p = rep(NA, t_max * r_max), run = as.factor(rep(1:r_max, each = t_max)))
  
  for (r in 1:r_max) {
    
    population <- tibble(trait = sample(c("A", "B"), N, replace = TRUE, prob = c(p_0, 1 - p_0)),
                     status = sample(c("high", "low"), N, replace = TRUE, prob = c(p_s, 1 - p_s))) 
    
    output[output$generation == 1 & output$run == r, ]$p <- sum(population$trait == "A") / N # add first generation's p for run r
    
    for (t in 2:t_max) {
      
      p_demonstrator <- rep(1,N)
      p_demonstrator[population$status == "low"] <- p_low
      
      if(sum(p_demonstrator) > 0){
        
        demonstrator_index <- sample (N, prob = p_demonstrator, replace = TRUE)
        
        population$trait <- population$trait[demonstrator_index]
      
      }
      output[output$generation == t & output$run == r, ]$p <- sum(population$trait == "A") / N # get p and put it into output slot for this generation t and run r
    }
    
  }
  output # export data from function
}
```

We can now test our simulation, assuming a very low, but not null, probability to select low-status individuals as demonstrators (remember we are using the habitual `plot_multiple_runs()` function to plot the results of the simulations).

```{r 5.6, echo=FALSE}
plot_multiple_runs <- function(data_model) {
  ggplot(data = data_model, aes(y = p, x = generation)) +
    geom_line(aes(colour = run)) +
    stat_summary(fun.y = mean, geom = "line", size = 1) +
    ylim(c(0, 1)) +
    theme_bw() +
    labs(y = "p (proportion of individuals with trait A)")
}
```

```{r 5.7}
data_model <- biased_transmission_demonstrator(N = 100, p_s = 0.05, p_low=0.0001, p_0 = 0.5, t_max = 50, r_max = 5)
plot_multiple_runs(data_model)
```

The results are similar to what we saw in the [previous chapter][Biased transmission (indirect bias: frequency)] for conformity: one of the two traits quickly reaches fixation. In the case of conformity, however, the trait reaching fixation was the one that happened to have a slightly higher frequency at the beginning, because of the random initialisation. With a demonstrator bias, this is not the case. 

From this perspective, an indirect, demonstrator-based, bias is more similar to unbiased transmission. If you remember from the [first chapter][Unbiased transmission], simulations with unbiased transmission also ended up with one trait reaching fixation with small populations ($N=100$), but with bigger ones ($N=10000$) the frequencies of the two traits remained around $p=0.5$. What does it happen with a demonstrator bias?  

```{r 5.8}
data_model <- biased_transmission_demonstrator(N = 10000, p_s = 0.005, p_low=0.0001, p_0 = 0.5, t_max = 200, r_max = 5)
plot_multiple_runs(data_model)
```

Even with $N=10000$, if the number of high-status individuals is sufficiently low, as in this case ($p_s=0.005$ means that, on average, 50 individuals are high-status in each run), traits reach fixation. By reducing the pool of demonstrators, demonstrator-based bias makes drift more important for the overall dynamics. You can experiment with different values of $p_s$ and $p_\text{low}$. How big can be the pool of high-status demonstrators before the dynamics become indistinguishable from unbiased transmission? 

## Predicting the 'winning' trait

With conformity, as just mentioned, the trait that reaches fixation is the one starting in majority, while with unbiased copying it can not be predicted at the beginning of the simulation. With a demonstrator bias, a reasonable guess would be that the 'winning' trait is the one that is, at the beginning, most common among the high-status individuals. Can we check this intuition with our model?

Currently the output we obtain from the simulations is not suitable to this purpose. On the one hand, we do not have a piece of information that we need, i.e. the proportion of high-status individuals having one of the two traits when the population is initialised. On the other, we have much information that we do not need, such as the frequency of the two traits at each time step (we just need to know which traits reach fixation). we can rewrite the function and only changing the `output` tibble to suit our needs.

```{r 5.9}
biased_transmission_demonstrator_2 <- function(N, p_0, p_s, p_low, t_max, r_max) {
  
  output <- tibble(status_A = rep(NA, r_max), p = rep(NA, r_max))
  
  for (r in 1:r_max) {
    
    population <- tibble(trait = sample(c("A", "B"), N, replace = TRUE, prob = c(p_0, 1 - p_0)),
                     status = sample(c("high", "low"), N, replace = TRUE, prob = c(p_s, 1 - p_s))) 
    
    output[r, ]$status_A <- sum(population$status == "high" & population$trait == "A") / 
      sum(population$status == "high")
    
    for (t in 2:t_max) {
      
      p_demonstrator <- rep(1,N)
      p_demonstrator[population$status == "low"] <- p_low
      
      if(sum(p_demonstrator) > 0){
        
        demonstrator_index <- sample (N, prob = p_demonstrator, replace = TRUE)
        
        population$trait <- population$trait[demonstrator_index]
      
      }
    }
  output[r, ]$p <- sum(population$trait == "A") / N     
  }
  output # export data from function
}
```

Let's run the new function, for 50 runs (change $r_\text{max}=50$) so to have more data points, and inspect the output.

```{r 5.10}
data_model <- biased_transmission_demonstrator_2(N = 100, p_s = 0.05, p_low=0.0001, p_0 = 0.5, t_max = 50, r_max = 50)
data_model
```

Each line of the output is a run of the simulation. In the first run, for example, 75% of high-status individuals had the trait $A$ at the beginning, and the frequency of the trait $A$ at the end of the simulation was 1, meaning it reached fixation. Generally, from a cursory inspection to the output, it seems our guess was correct. But let's visualise all the data.   

We want to know how the initial proportion of high-status individuals is related to the two possible outcomes (trait $A$ reaches fixation and trait $B$ reaches fixation). A convenient way is to use a boxplot. In the code below, we first eliminate the runs where the traits did not reach fixation (in case they exist) using the new function `filter()`, and, for clarity, we assign the trait name ($A$ or $B$) to each run according to which trait reached fixation. We can then plot our output (in this case, we do not write a function on purpose). The main novelties in the code are the new ggplot 'geoms' `geom_boxplot()` and `geom_jitter()`. Whereas boxplots are useful to detect aggregate information on our simulations, `geom_jitter()` plots also the single data points, so we can have a better idea on how the proportions of high-status individuals are distributed in the various runs. We could have done this with our usual `geom_point()`, but `geom_jitter()` scatters randomly (at a distance specified by the parameter `width`) the points in the plot. This allows to avoid the overlapping of individual data points (known as overplotting). 

```{r 5.11}
data_model <- filter(data_model, p == 1 | p == 0)
data_model[data_model$p==1, ]$p <- "A"
data_model[data_model$p==0, ]$p <- "B"

ggplot(data = data_model, aes(x = p, y = status_A, fill = p)) +
  geom_boxplot() +
  geom_jitter(width = 0.05) +
  labs(y = "proportion of high-status individuals with trait A", 
       x = "winning trait") +
  ylim(c(0,1)) +
  theme_bw() +
  theme(legend.position = "none") 
```

The plot shows that when the trait $A$ reaches fixation there are in general more high-status individuals with trait $A$ at the beginning, and vice versa for $B$, confirming our intuition. However, this is far from being a safe bet. Runs with only a quarter of high-status individuals with $A$ ended up with all $A$s in the population and, conversely, runs with $80%$ of high-status individuals with $A$ ended up with the fixation of $B$. With bigger populations, it is even worst.

```{r 5.12}
data_model <- biased_transmission_demonstrator_2(N = 10000, p_s = 0.005, p_low=0.0001, p_0 = 0.5, t_max = 200, r_max = 50)

data_model <- filter(data_model, p == 1 | p == 0)
data_model[data_model$p==1, ]$p <- "A"
data_model[data_model$p==0, ]$p <- "B"

ggplot(data = data_model, aes(x = p, y = status_A, fill = p)) +
  geom_boxplot() +
  geom_jitter(width = 0.05) +
  labs(y = "proportion of high-status individuals with trait A", 
       x = "winning trait") +
  ylim(c(0,1)) +
  theme_bw() +
  theme(legend.position = "none") 
```

With $N=10000$ and around 50 high-status individuals, the traits are more equally distributed among 'influential' demonstrators at the beginning, and there is hardly any difference in the two outcomes.   

***

## Summary of the model

In this chapter we modeled an example of indirect, demonstrator-based, biased transmission. We assumed that a fraction of individuals in the population was 'high-status' and thus more likely to be selected as demonstrators. The results show that in this situation a trait is likely to become predominant even when populations are large. This is due to the fact that a demonstrator bias effectively works reducing the pool of demonstrators and accelerating convergence. We also saw that the possibility of predicting which trait will become predominant depends on the number of high-status demonstrators. When there are few of them is likely that the trait that they posses in majority will go to fixation, but when their number increase, it is more difficult to make prediction.  

We also saw how it is important to modify the output of a model depending on the question we are interested in, and we used for the first time ggplot to produce boxplot, a convenient way of displaying the distribution of data along different groups.

***

## Analytical appendix

IS THERE ANYHTIHG WE CAN DO HERE?

***

## Further readings

Test @mesoudi_cultural_2009 

Test @henrich_joseph_big_2015

Test @boyd_culture_1985

Test @jimenez_prestige-biased_2019


